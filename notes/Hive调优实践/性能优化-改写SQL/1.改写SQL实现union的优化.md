# 改写SQL实现union的优化

```sql
select
    id
    ,max(stt) as time_out
from online
group by 
    id 
union all 
select
    id
    ,min(stt) as time_out
from online
group by 
    id 
```

## explain执行计划

```sql
-- 4个任务依赖
STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-2 depends on stages: Stage-1, Stage-3
  Stage-3 is a root stage
  Stage-0 depends on stages: Stage-2

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: online
            Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: id (type: string), stt (type: string)
              outputColumnNames: id, stt
              Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: max(stt)
                keys: id (type: string)
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string)
      Execution mode: vectorized
      Reduce Operator Tree:
        Group By Operator
          aggregations: max(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-2
    Map Reduce
      Map Operator Tree:
          TableScan
            Union
              Statistics: Num rows: 2 Data size: 7200 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 2 Data size: 7200 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
          TableScan
            Union
              Statistics: Num rows: 2 Data size: 7200 Basic stats: COMPLETE Column stats: NONE
              File Output Operator
                compressed: false
                Statistics: Num rows: 2 Data size: 7200 Basic stats: COMPLETE Column stats: NONE
                table:
                    input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                    output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-3
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: online
            Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
            Select Operator
              expressions: id (type: string), stt (type: string)
              outputColumnNames: id, stt
              Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: min(stt)
                keys: id (type: string)
                mode: hash
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  key expressions: _col0 (type: string)
                  sort order: +
                  Map-reduce partition columns: _col0 (type: string)
                  Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col1 (type: string)
      Execution mode: vectorized
      Reduce Operator Tree:
        Group By Operator
          aggregations: min(VALUE._col0)
          keys: KEY._col0 (type: string)
          mode: mergepartial
          outputColumnNames: _col0, _col1
          Statistics: Num rows: 1 Data size: 3600 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

Time taken: 0.222 seconds, Fetched: 111 row(s)
```

由上面的执行计划可知，总共有4个任务：

1. 任务1，取online表数据，计算stt的max值，并写入临时区。 
2. 任务2，取online表数据，计算stt的min值，并写入临时区。
3. 任务3，求任务1和任务2结果的并集。
4. 任务4，把任务3得到的结果输出到控制台上。

那么，我们是怎么知道是上面的四个任务，不是其他的任务呢？

有两种方式可以判断： 

* 第一，通过查看执行计划，但是一定要记住一点，Hive的执行计划都是预测的，这点不像Oracle和SQL Server有真实的计划，在后面我们会详细谈谈执行计划；
* 第二，按照SQL语法，结合MapReduce的实现机制去推测MR应该怎么实现，这种方式需要建立在有一定MapReduce编写经验上，理解基本的分布式计算基本原理。

HiveSQL在执行时会转化为各种计算引擎能够运行的算子。作为HiveSQL的使用者者， 想要写出更加有效率的HiveSQL代码和MR代码，就需要去理解HiveSQL是如何转化为各种计算引擎所能运行的算子的。

这对于使用者来说，是有一定的挑战，却又是想要提升自己优化能力所必须的能力。所以，我们可以分两步达到达到这个目标：

1. 理解基本的MR过程和原理；
2. 在平时写SQL的过程中，尝试将SQL拆解成计算引擎对应的算子，拆解完和执行计划对比，还要和实际执行过程的算子对比，并思考自己拆解完后的算子与通过explain方式得到的算子的执行计划有什么差异。